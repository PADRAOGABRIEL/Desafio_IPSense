{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa de Predição se o asteroide é perigoso ou não"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da função para retornar as métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asteroids = pd.read_csv('../data/df_asteroids_st2.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_true, y_pred, features, sampling, model, sampling_method):\n",
    "\n",
    "    if sampling_method == 'undersampling':\n",
    "        sampling_method = f'US - {sampling}'  # Descreve a taxa de balanceamento\n",
    "    elif sampling_method == 'oversampling':\n",
    "        sampling_method = f'ADASYN - {sampling}'  # Método de amostragem ADASYN\n",
    "    else:\n",
    "        sampling_method = 'class_weight'\n",
    "        \n",
    "    return {\n",
    "        \"Features\": features,\n",
    "        \"Algoritmo\": str(model),\n",
    "        \"Acurácia\": round(accuracy_score(y_true, y_pred),3),\n",
    "        \"Precisão\": round(precision_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"Recall\": round(recall_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"F1-Score\": round(f1_score(y_true, y_pred),3),\n",
    "        \"AUC-ROC\": round(roc_auc_score(y_true, y_pred),3),\n",
    "        \"Método\": str(sampling_method)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis para inputar nos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = [0.5, 0.6, 0.7]\n",
    "sampling_method = ['undersampling', 'oversampling', 'class_weight']\n",
    "model = [DT(random_state=0), RF(random_state=0), LR(random_state=0, max_iter=200), XGB(random_state=0)]\n",
    "\n",
    "features = ['feat1', ['relative_velocity_kmh', 'estimated_diameter_mean', 'miss_distance_km', 'absolute_magnitude_h', 'is_sentry_object']]\n",
    "\n",
    "products = []\n",
    "for method in sampling_method:\n",
    "    for samp in (sampling if method != 'class_weight' else [1]):\n",
    "            for mod in model:\n",
    "                    products.append({\n",
    "                        'sampling_method': method,\n",
    "                        'sampling': samp,\n",
    "                        'model': mod,\n",
    "                        'feature': features\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as combinações de variáveis  \n",
    "Gerando um total de 27 modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_method</th>\n",
       "      <th>sampling</th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampling_method  sampling   \n",
       "0    undersampling       0.5  \\\n",
       "1    undersampling       0.5   \n",
       "2    undersampling       0.5   \n",
       "3    undersampling       0.5   \n",
       "4    undersampling       0.6   \n",
       "5    undersampling       0.6   \n",
       "6    undersampling       0.6   \n",
       "7    undersampling       0.6   \n",
       "8    undersampling       0.7   \n",
       "9    undersampling       0.7   \n",
       "10   undersampling       0.7   \n",
       "11   undersampling       0.7   \n",
       "12    oversampling       0.5   \n",
       "13    oversampling       0.5   \n",
       "14    oversampling       0.5   \n",
       "15    oversampling       0.5   \n",
       "16    oversampling       0.6   \n",
       "17    oversampling       0.6   \n",
       "18    oversampling       0.6   \n",
       "19    oversampling       0.6   \n",
       "20    oversampling       0.7   \n",
       "21    oversampling       0.7   \n",
       "22    oversampling       0.7   \n",
       "23    oversampling       0.7   \n",
       "24    class_weight       1.0   \n",
       "25    class_weight       1.0   \n",
       "26    class_weight       1.0   \n",
       "27    class_weight       1.0   \n",
       "\n",
       "                                                model   \n",
       "0              DecisionTreeClassifier(random_state=0)  \\\n",
       "1              RandomForestClassifier(random_state=0)   \n",
       "2    LogisticRegression(max_iter=200, random_state=0)   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "4              DecisionTreeClassifier(random_state=0)   \n",
       "5              RandomForestClassifier(random_state=0)   \n",
       "6    LogisticRegression(max_iter=200, random_state=0)   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8              DecisionTreeClassifier(random_state=0)   \n",
       "9              RandomForestClassifier(random_state=0)   \n",
       "10   LogisticRegression(max_iter=200, random_state=0)   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "12             DecisionTreeClassifier(random_state=0)   \n",
       "13             RandomForestClassifier(random_state=0)   \n",
       "14   LogisticRegression(max_iter=200, random_state=0)   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16             DecisionTreeClassifier(random_state=0)   \n",
       "17             RandomForestClassifier(random_state=0)   \n",
       "18   LogisticRegression(max_iter=200, random_state=0)   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "20             DecisionTreeClassifier(random_state=0)   \n",
       "21             RandomForestClassifier(random_state=0)   \n",
       "22   LogisticRegression(max_iter=200, random_state=0)   \n",
       "23  XGBClassifier(base_score=None, booster=None, c...   \n",
       "24             DecisionTreeClassifier(random_state=0)   \n",
       "25             RandomForestClassifier(random_state=0)   \n",
       "26   LogisticRegression(max_iter=200, random_state=0)   \n",
       "27  XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                                              feature  \n",
       "0   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "1   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "2   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "3   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "4   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "5   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "6   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "7   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "8   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "9   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "10  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "11  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "12  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "13  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "14  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "15  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "16  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "17  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "18  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "19  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "20  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "21  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "22  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "23  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "24  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "25  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "26  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "27  [feat1, [relative_velocity_kmh, estimated_diam...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função principal para a criação dos modelos preditivos e testes   \n",
    "Função baseada no RMMS[Giusti et al. 2022] (REGRESSIVE MULTI-DIMENSIONAL MODEL SELECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_predictions(df, features, model, sampling=None, sampling_method=None, return_model=False):\n",
    "\n",
    "    X = df[features[1]]\n",
    "    y = df['is_potentially_hazardous']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    if sampling_method == \"undersampling\":\n",
    "        y_train = pd.concat([y_train[y_train==1], y_train[y_train==0].sample(int((len(y_train[y_train == 1]) * sampling)/(1 - sampling)), random_state=0)])\n",
    "        X_train = X_train.loc[y_train.index]\n",
    "    elif sampling_method == \"oversampling\":\n",
    "        ada = ADASYN(sampling_strategy=sampling, random_state=0)\n",
    "        X_train, y_train = ada.fit_resample(X_train, y_train)\n",
    "    elif sampling_method == \"class_weight\":\n",
    "        model.set_params(class_weight='balanced')\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predições após o treinamento\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if return_model:\n",
    "        return model, y_pred, X_test, y_test, df\n",
    "    else:\n",
    "        # Métricas avaliativas comparando o conjunto de teste e o conjunto previsto\n",
    "        result = scores(y_test, y_pred, features[0], sampling, model, sampling_method=sampling_method)   \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada da função principal e armazenamento dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:52:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for product in products:\n",
    "                results.append(classification_predictions(\n",
    "                    df_asteroids, \n",
    "                    features=product['feature'], \n",
    "                    model=product['model'], \n",
    "                    sampling=product['sampling'], \n",
    "                    sampling_method=product['sampling_method'], \n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando os resultados e ordenando pelo F1-Score e salvando no arquivo 'results_ml_st3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Precisão</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Método</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.846</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.824</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.781</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.903</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.765</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.780</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.874</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.865</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.766</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.871</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.822</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.749</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.899</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.747</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.851</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.887</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.791</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.838</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.656</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.769</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.693</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.790</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.753</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.706</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.678</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.601</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.670</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.589</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features                                          Algoritmo  Acurácia   \n",
       "0     feat1             RandomForestClassifier(random_state=0)     0.893  \\\n",
       "1     feat1             RandomForestClassifier(random_state=0)     0.897   \n",
       "2     feat1  XGBClassifier(base_score=None, booster=None, c...     0.904   \n",
       "3     feat1             RandomForestClassifier(random_state=0)     0.847   \n",
       "4     feat1             DecisionTreeClassifier(random_state=0)     0.902   \n",
       "5     feat1             RandomForestClassifier(random_state=0)     0.893   \n",
       "6     feat1  XGBClassifier(base_score=None, booster=None, c...     0.849   \n",
       "7     feat1             RandomForestClassifier(random_state=0)     0.852   \n",
       "8     feat1  XGBClassifier(base_score=None, booster=None, c...     0.894   \n",
       "9     feat1             DecisionTreeClassifier(random_state=0)     0.844   \n",
       "10    feat1  XGBClassifier(base_score=None, booster=None, c...     0.866   \n",
       "11    feat1             DecisionTreeClassifier(random_state=0)     0.900   \n",
       "12    feat1             RandomForestClassifier(random_state=0)     0.829   \n",
       "13    feat1  XGBClassifier(base_score=None, booster=None, c...     0.897   \n",
       "14    feat1             DecisionTreeClassifier(random_state=0)     0.845   \n",
       "15    feat1  XGBClassifier(base_score=None, booster=None, c...     0.827   \n",
       "16    feat1             DecisionTreeClassifier(random_state=0)     0.865   \n",
       "17    feat1   LogisticRegression(max_iter=200, random_state=0)     0.830   \n",
       "18    feat1  DecisionTreeClassifier(class_weight='balanced'...     0.925   \n",
       "19    feat1   LogisticRegression(max_iter=200, random_state=0)     0.853   \n",
       "20    feat1             DecisionTreeClassifier(random_state=0)     0.899   \n",
       "21    feat1  LogisticRegression(class_weight='balanced', ma...     0.825   \n",
       "22    feat1   LogisticRegression(max_iter=200, random_state=0)     0.851   \n",
       "23    feat1   LogisticRegression(max_iter=200, random_state=0)     0.857   \n",
       "24    feat1   LogisticRegression(max_iter=200, random_state=0)     0.871   \n",
       "25    feat1  XGBClassifier(base_score=None, booster=None, c...     0.937   \n",
       "26    feat1   LogisticRegression(max_iter=200, random_state=0)     0.866   \n",
       "27    feat1  RandomForestClassifier(class_weight='balanced'...     0.943   \n",
       "\n",
       "    Precisão  Recall  F1-Score  AUC-ROC        Método  \n",
       "0      0.348   0.793     0.483    0.846  ADASYN - 0.7  \n",
       "1      0.352   0.739     0.477    0.824  ADASYN - 0.6  \n",
       "2      0.355   0.641     0.457    0.781  ADASYN - 0.5  \n",
       "3      0.289   0.967     0.445    0.903      US - 0.6  \n",
       "4      0.344   0.609     0.439    0.765  ADASYN - 0.7  \n",
       "5      0.326   0.652     0.435    0.780  ADASYN - 0.5  \n",
       "6      0.283   0.902     0.431    0.874      US - 0.6  \n",
       "7      0.284   0.880     0.430    0.865      US - 0.7  \n",
       "8      0.324   0.620     0.425    0.766  ADASYN - 0.7  \n",
       "9      0.277   0.902     0.423    0.871      US - 0.5  \n",
       "10     0.291   0.772     0.423    0.822      US - 0.7  \n",
       "11     0.333   0.576     0.422    0.749  ADASYN - 0.5  \n",
       "12     0.268   0.978     0.421    0.899      US - 0.5  \n",
       "13     0.323   0.576     0.414    0.747  ADASYN - 0.6  \n",
       "14     0.271   0.859     0.413    0.851      US - 0.6  \n",
       "15     0.263   0.957     0.412    0.887      US - 0.5  \n",
       "16     0.278   0.707     0.399    0.791      US - 0.7  \n",
       "17     0.251   0.848     0.387    0.838      US - 0.5  \n",
       "18     0.395   0.348     0.370    0.656  class_weight  \n",
       "19     0.252   0.674     0.367    0.769      US - 0.6  \n",
       "20     0.304   0.457     0.365    0.693  ADASYN - 0.6  \n",
       "21     0.230   0.750     0.352    0.790  class_weight  \n",
       "22     0.243   0.641     0.352    0.753  ADASYN - 0.7  \n",
       "23     0.229   0.533     0.320    0.706  ADASYN - 0.6  \n",
       "24     0.235   0.457     0.310    0.678      US - 0.7  \n",
       "25     0.500   0.217     0.303    0.601  class_weight  \n",
       "26     0.223   0.446     0.297    0.670  ADASYN - 0.5  \n",
       "27     0.680   0.185     0.291    0.589  class_weight  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('../data/results_ml_st3.csv')\n",
    "df_results.sort_values('F1-Score', ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
