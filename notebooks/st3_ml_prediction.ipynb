{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from xgboost import XGBClassifier as XGB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentativa de Predição se o asteroide é perigoso ou não"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da função para retornar as métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asteroids = pd.read_csv('../data/df_asteroids_st2.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_true, y_pred, features, sampling, model, sampling_method):\n",
    "\n",
    "    if sampling_method == 'undersampling':\n",
    "        sampling_method = f'US - {sampling}'  # Descreve a taxa de balanceamento\n",
    "    elif sampling_method == 'oversampling':\n",
    "        sampling_method = f'ADASYN - {sampling}'  # Método de amostragem ADASYN\n",
    "    else:\n",
    "        sampling_method = 'class_weight'\n",
    "        \n",
    "    return {\n",
    "        \"Features\": features,\n",
    "        \"Algoritmo\": str(model),\n",
    "        \"Acurácia\": round(accuracy_score(y_true, y_pred),3),\n",
    "        \"Precisão\": round(precision_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"Recall\": round(recall_score(y_true, y_pred, zero_division=0), 3),\n",
    "        \"F1-Score\": round(f1_score(y_true, y_pred),3),\n",
    "        \"AUC-ROC\": round(roc_auc_score(y_true, y_pred),3),\n",
    "        \"Método\": str(sampling_method)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variáveis para inputar nos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = [0.5, 0.6, 0.7]\n",
    "sampling_method = ['undersampling', 'oversampling', 'class_weight']\n",
    "model = [DT(random_state=0), RF(random_state=0), LR(random_state=0, max_iter=200), XGB(random_state=0)]\n",
    "\n",
    "features = ['feat1', ['relative_velocity_kmh', 'estimated_diameter_mean', 'miss_distance_km', 'absolute_magnitude_h', 'is_sentry_object']]\n",
    "\n",
    "products = []\n",
    "for method in sampling_method:\n",
    "    for samp in (sampling if method != 'class_weight' else [1]):\n",
    "            for mod in model:\n",
    "                    products.append({\n",
    "                        'sampling_method': method,\n",
    "                        'sampling': samp,\n",
    "                        'model': mod,\n",
    "                        'feature': features\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as combinações de variáveis  \n",
    "Gerando um total de 27 modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_method</th>\n",
       "      <th>sampling</th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>undersampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.6</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>oversampling</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LogisticRegression(max_iter=200, random_state=0)</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>[feat1, [relative_velocity_kmh, estimated_diam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampling_method  sampling   \n",
       "0    undersampling       0.5  \\\n",
       "1    undersampling       0.5   \n",
       "2    undersampling       0.5   \n",
       "3    undersampling       0.5   \n",
       "4    undersampling       0.6   \n",
       "5    undersampling       0.6   \n",
       "6    undersampling       0.6   \n",
       "7    undersampling       0.6   \n",
       "8    undersampling       0.7   \n",
       "9    undersampling       0.7   \n",
       "10   undersampling       0.7   \n",
       "11   undersampling       0.7   \n",
       "12    oversampling       0.5   \n",
       "13    oversampling       0.5   \n",
       "14    oversampling       0.5   \n",
       "15    oversampling       0.5   \n",
       "16    oversampling       0.6   \n",
       "17    oversampling       0.6   \n",
       "18    oversampling       0.6   \n",
       "19    oversampling       0.6   \n",
       "20    oversampling       0.7   \n",
       "21    oversampling       0.7   \n",
       "22    oversampling       0.7   \n",
       "23    oversampling       0.7   \n",
       "24    class_weight       1.0   \n",
       "25    class_weight       1.0   \n",
       "26    class_weight       1.0   \n",
       "27    class_weight       1.0   \n",
       "\n",
       "                                                model   \n",
       "0              DecisionTreeClassifier(random_state=0)  \\\n",
       "1              RandomForestClassifier(random_state=0)   \n",
       "2    LogisticRegression(max_iter=200, random_state=0)   \n",
       "3   XGBClassifier(base_score=None, booster=None, c...   \n",
       "4              DecisionTreeClassifier(random_state=0)   \n",
       "5              RandomForestClassifier(random_state=0)   \n",
       "6    LogisticRegression(max_iter=200, random_state=0)   \n",
       "7   XGBClassifier(base_score=None, booster=None, c...   \n",
       "8              DecisionTreeClassifier(random_state=0)   \n",
       "9              RandomForestClassifier(random_state=0)   \n",
       "10   LogisticRegression(max_iter=200, random_state=0)   \n",
       "11  XGBClassifier(base_score=None, booster=None, c...   \n",
       "12             DecisionTreeClassifier(random_state=0)   \n",
       "13             RandomForestClassifier(random_state=0)   \n",
       "14   LogisticRegression(max_iter=200, random_state=0)   \n",
       "15  XGBClassifier(base_score=None, booster=None, c...   \n",
       "16             DecisionTreeClassifier(random_state=0)   \n",
       "17             RandomForestClassifier(random_state=0)   \n",
       "18   LogisticRegression(max_iter=200, random_state=0)   \n",
       "19  XGBClassifier(base_score=None, booster=None, c...   \n",
       "20             DecisionTreeClassifier(random_state=0)   \n",
       "21             RandomForestClassifier(random_state=0)   \n",
       "22   LogisticRegression(max_iter=200, random_state=0)   \n",
       "23  XGBClassifier(base_score=None, booster=None, c...   \n",
       "24             DecisionTreeClassifier(random_state=0)   \n",
       "25             RandomForestClassifier(random_state=0)   \n",
       "26   LogisticRegression(max_iter=200, random_state=0)   \n",
       "27  XGBClassifier(base_score=None, booster=None, c...   \n",
       "\n",
       "                                              feature  \n",
       "0   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "1   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "2   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "3   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "4   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "5   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "6   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "7   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "8   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "9   [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "10  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "11  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "12  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "13  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "14  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "15  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "16  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "17  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "18  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "19  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "20  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "21  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "22  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "23  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "24  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "25  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "26  [feat1, [relative_velocity_kmh, estimated_diam...  \n",
       "27  [feat1, [relative_velocity_kmh, estimated_diam...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função principal para a criação dos modelos preditivos e testes   \n",
    "Função baseada no RMMS[Giusti et al. 2022] (REGRESSIVE MULTI-DIMENSIONAL MODEL SELECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_predictions(df, features, model, sampling=None, sampling_method=None):\n",
    "\n",
    "    X = df[features[1]]\n",
    "    y = df['is_potentially_hazardous']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    if sampling_method == \"undersampling\":\n",
    "        y_train = pd.concat([y_train[y_train==1], y_train[y_train==0].sample(int((len(y_train[y_train == 1]) * sampling)/(1 - sampling)), random_state=0)])\n",
    "        X_train = X_train.loc[y_train.index]\n",
    "    elif sampling_method == \"oversampling\":\n",
    "        ada = ADASYN(sampling_strategy=sampling, random_state=0)\n",
    "        X_train, y_train = ada.fit_resample(X_train, y_train)\n",
    "    elif sampling_method == \"class_weight\":\n",
    "        model.set_params(class_weight='balanced')\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predições após o treinamento\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Métricas avaliativas comparando o conjunto de teste e o conjunto previsto\n",
    "    result = scores(y_test, y_pred, features[0], sampling, model, sampling_method=sampling_method)   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada da função principal e armazenamento dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for product in products:\n",
    "                results.append(classification_predictions(\n",
    "                    df_asteroids, \n",
    "                    features=product['feature'], \n",
    "                    model=product['model'], \n",
    "                    sampling=product['sampling'], \n",
    "                    sampling_method=product['sampling_method'], \n",
    "                ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando os resultados e ordenando pelo F1-Score e salvando no arquivo 'results_ml_st3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Algoritmo</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Precisão</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Método</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.847</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.816</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.803</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.781</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.789</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.869</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.898</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.854</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.874</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.766</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.871</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.822</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.899</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.744</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.747</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.887</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.788</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.702</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.838</td>\n",
       "      <td>US - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.815</td>\n",
       "      <td>US - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.809</td>\n",
       "      <td>US - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>feat1</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.656</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.790</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.786</td>\n",
       "      <td>ADASYN - 0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.786</td>\n",
       "      <td>ADASYN - 0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feat1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.790</td>\n",
       "      <td>ADASYN - 0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feat1</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.601</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>feat1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.589</td>\n",
       "      <td>class_weight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features                                          Algoritmo  Acurácia   \n",
       "0     feat1  RandomForestClassifier(class_weight='balanced'...     0.894  \\\n",
       "1     feat1  RandomForestClassifier(class_weight='balanced'...     0.893   \n",
       "2     feat1  RandomForestClassifier(class_weight='balanced'...     0.897   \n",
       "3     feat1  XGBClassifier(base_score=None, booster=None, c...     0.904   \n",
       "4     feat1  DecisionTreeClassifier(class_weight='balanced'...     0.899   \n",
       "5     feat1  DecisionTreeClassifier(class_weight='balanced'...     0.860   \n",
       "6     feat1  RandomForestClassifier(class_weight='balanced'...     0.846   \n",
       "7     feat1  RandomForestClassifier(class_weight='balanced'...     0.859   \n",
       "8     feat1  XGBClassifier(base_score=None, booster=None, c...     0.849   \n",
       "9     feat1  XGBClassifier(base_score=None, booster=None, c...     0.894   \n",
       "10    feat1  DecisionTreeClassifier(class_weight='balanced'...     0.844   \n",
       "11    feat1  XGBClassifier(base_score=None, booster=None, c...     0.866   \n",
       "12    feat1  RandomForestClassifier(class_weight='balanced'...     0.829   \n",
       "13    feat1  DecisionTreeClassifier(class_weight='balanced'...     0.900   \n",
       "14    feat1  XGBClassifier(base_score=None, booster=None, c...     0.897   \n",
       "15    feat1  XGBClassifier(base_score=None, booster=None, c...     0.827   \n",
       "16    feat1  DecisionTreeClassifier(class_weight='balanced'...     0.860   \n",
       "17    feat1  DecisionTreeClassifier(class_weight='balanced'...     0.906   \n",
       "18    feat1  LogisticRegression(class_weight='balanced', ma...     0.830   \n",
       "19    feat1  LogisticRegression(class_weight='balanced', ma...     0.833   \n",
       "20    feat1  LogisticRegression(class_weight='balanced', ma...     0.833   \n",
       "21    feat1  DecisionTreeClassifier(class_weight='balanced'...     0.925   \n",
       "22    feat1  LogisticRegression(class_weight='balanced', ma...     0.825   \n",
       "23    feat1  LogisticRegression(class_weight='balanced', ma...     0.827   \n",
       "24    feat1  LogisticRegression(class_weight='balanced', ma...     0.826   \n",
       "25    feat1  LogisticRegression(class_weight='balanced', ma...     0.824   \n",
       "26    feat1  XGBClassifier(base_score=None, booster=None, c...     0.937   \n",
       "27    feat1  RandomForestClassifier(class_weight='balanced'...     0.943   \n",
       "\n",
       "    Precisão  Recall  F1-Score  AUC-ROC        Método  \n",
       "0      0.351   0.793     0.487    0.847  ADASYN - 0.7  \n",
       "1      0.338   0.728     0.462    0.816  ADASYN - 0.6  \n",
       "2      0.346   0.696     0.462    0.803  ADASYN - 0.5  \n",
       "3      0.355   0.641     0.457    0.781  ADASYN - 0.5  \n",
       "4      0.347   0.663     0.455    0.789  ADASYN - 0.7  \n",
       "5      0.296   0.880     0.443    0.869      US - 0.6  \n",
       "6      0.287   0.957     0.441    0.898      US - 0.6  \n",
       "7      0.290   0.848     0.432    0.854      US - 0.7  \n",
       "8      0.283   0.902     0.431    0.874      US - 0.6  \n",
       "9      0.324   0.620     0.425    0.766  ADASYN - 0.7  \n",
       "10     0.277   0.902     0.423    0.871      US - 0.5  \n",
       "11     0.291   0.772     0.423    0.822      US - 0.7  \n",
       "12     0.268   0.978     0.421    0.899      US - 0.5  \n",
       "13     0.331   0.565     0.418    0.744  ADASYN - 0.5  \n",
       "14     0.323   0.576     0.414    0.747  ADASYN - 0.6  \n",
       "15     0.263   0.957     0.412    0.887      US - 0.5  \n",
       "16     0.269   0.707     0.389    0.788      US - 0.7  \n",
       "17     0.331   0.467     0.387    0.702  ADASYN - 0.6  \n",
       "18     0.251   0.848     0.387    0.838      US - 0.5  \n",
       "19     0.247   0.793     0.376    0.815      US - 0.6  \n",
       "20     0.244   0.783     0.372    0.809      US - 0.7  \n",
       "21     0.395   0.348     0.370    0.656  class_weight  \n",
       "22     0.230   0.750     0.352    0.790  class_weight  \n",
       "23     0.231   0.739     0.351    0.786  ADASYN - 0.5  \n",
       "24     0.230   0.739     0.351    0.786  ADASYN - 0.7  \n",
       "25     0.229   0.750     0.351    0.790  ADASYN - 0.6  \n",
       "26     0.500   0.217     0.303    0.601  class_weight  \n",
       "27     0.680   0.185     0.291    0.589  class_weight  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('../data/results_ml_st3.csv')\n",
    "df_results.sort_values('F1-Score', ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
